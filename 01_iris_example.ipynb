{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83c31ed7-7e8c-409d-9e9f-babcd95971df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import urllib\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.ml.feature import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "889f7328-820f-4b53-9b68-3c25ce104e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('example').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4c8fc66-629b-4e2f-9609-c05dede5cde1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('iris.csv', <http.client.HTTPMessage at 0x40711a6aa0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "urllib.request.urlretrieve(URL, \"iris.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8261b63c-c5d0-4584-a62f-f7ab9bd25037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sepal-length: double (nullable = true)\n",
      " |-- sepal-width: double (nullable = true)\n",
      " |-- petal-length: double (nullable = true)\n",
      " |-- petal-width: double (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
    "\n",
    "# inferSchema reads the file twice, but detects numerical columns\n",
    "data = spark.read.csv('iris.csv', header=False, inferSchema=True)\n",
    "data = data.toDF(*columns)\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3604876b-004e-4d2a-9b02-e8d0e5823b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can also create from a pandas dataframe\n",
    "data = spark.createDataFrame(pd.read_csv('iris.csv', header=None, names=['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']))\n",
    "data.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aeacda-8546-4fc3-9f6c-a8c9eaee1d92",
   "metadata": {},
   "source": [
    "## Linear Classifier\n",
    "\n",
    "To perform Machine Learning, you need to select features into a single vector column, and transform the target column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31826b45-6d7e-4c1c-bc3c-2e4d6b37d112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------+-----------------+\n",
      "|sepal-length|sepal-width|petal-length|petal-width|      class|         features|\n",
      "+------------+-----------+------------+-----------+-----------+-----------------+\n",
      "|         5.1|        3.5|         1.4|        0.2|Iris-setosa|[5.1,3.5,1.4,0.2]|\n",
      "|         4.9|        3.0|         1.4|        0.2|Iris-setosa|[4.9,3.0,1.4,0.2]|\n",
      "|         4.7|        3.2|         1.3|        0.2|Iris-setosa|[4.7,3.2,1.3,0.2]|\n",
      "|         4.6|        3.1|         1.5|        0.2|Iris-setosa|[4.6,3.1,1.5,0.2]|\n",
      "|         5.0|        3.6|         1.4|        0.2|Iris-setosa|[5.0,3.6,1.4,0.2]|\n",
      "|         5.4|        3.9|         1.7|        0.4|Iris-setosa|[5.4,3.9,1.7,0.4]|\n",
      "|         4.6|        3.4|         1.4|        0.3|Iris-setosa|[4.6,3.4,1.4,0.3]|\n",
      "|         5.0|        3.4|         1.5|        0.2|Iris-setosa|[5.0,3.4,1.5,0.2]|\n",
      "|         4.4|        2.9|         1.4|        0.2|Iris-setosa|[4.4,2.9,1.4,0.2]|\n",
      "|         4.9|        3.1|         1.5|        0.1|Iris-setosa|[4.9,3.1,1.5,0.1]|\n",
      "+------------+-----------+------------+-----------+-----------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create feature column\n",
    "\n",
    "feature_cols = data.columns[:-1]\n",
    "assembler = pyspark.ml.feature.VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
    "data = assembler.transform(data)\n",
    "data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e90c377-f23a-4aed-a4d3-534d140e55d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+-----+\n",
      "|         features|      class|label|\n",
      "+-----------------+-----------+-----+\n",
      "|[5.1,3.5,1.4,0.2]|Iris-setosa|  0.0|\n",
      "|[4.9,3.0,1.4,0.2]|Iris-setosa|  0.0|\n",
      "|[4.7,3.2,1.3,0.2]|Iris-setosa|  0.0|\n",
      "|[4.6,3.1,1.5,0.2]|Iris-setosa|  0.0|\n",
      "|[5.0,3.6,1.4,0.2]|Iris-setosa|  0.0|\n",
      "|[5.4,3.9,1.7,0.4]|Iris-setosa|  0.0|\n",
      "|[4.6,3.4,1.4,0.3]|Iris-setosa|  0.0|\n",
      "|[5.0,3.4,1.5,0.2]|Iris-setosa|  0.0|\n",
      "|[4.4,2.9,1.4,0.2]|Iris-setosa|  0.0|\n",
      "|[4.9,3.1,1.5,0.1]|Iris-setosa|  0.0|\n",
      "+-----------------+-----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert text labels into indices\n",
    "\n",
    "data = data.select(['features', 'class'])\n",
    "label_indexer = pyspark.ml.feature.StringIndexer(inputCol='class', outputCol='label').fit(data)\n",
    "data = label_indexer.transform(data)\n",
    "data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4062749d-4818-4ff7-929d-f9bc7f239674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading for machine learning\n",
      "+-----------------+-----+\n",
      "|         features|label|\n",
      "+-----------------+-----+\n",
      "|[5.1,3.5,1.4,0.2]|  0.0|\n",
      "|[4.9,3.0,1.4,0.2]|  0.0|\n",
      "|[4.7,3.2,1.3,0.2]|  0.0|\n",
      "|[4.6,3.1,1.5,0.2]|  0.0|\n",
      "|[5.0,3.6,1.4,0.2]|  0.0|\n",
      "|[5.4,3.9,1.7,0.4]|  0.0|\n",
      "|[4.6,3.4,1.4,0.3]|  0.0|\n",
      "|[5.0,3.4,1.5,0.2]|  0.0|\n",
      "|[4.4,2.9,1.4,0.2]|  0.0|\n",
      "|[4.9,3.1,1.5,0.1]|  0.0|\n",
      "+-----------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# only select the features and label column\n",
    "\n",
    "data = data.select(['features', 'label'])\n",
    "print(\"Reading for machine learning\")\n",
    "data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84f3bd12-7ba2-4c3d-9938-9f6dc46f2c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Logistic Regression to train on the training set\n",
    "\n",
    "train, test = data.randomSplit([0.70, 0.30])\n",
    "lr = pyspark.ml.classification.LogisticRegression(regParam=0.01)\n",
    "model = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d38f1870-cb7b-4f61-87f3-1715fcffd564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "+-----------------+-----+--------------------+--------------------+----------+\n",
      "|         features|label|       rawPrediction|         probability|prediction|\n",
      "+-----------------+-----+--------------------+--------------------+----------+\n",
      "|[4.3,3.0,1.1,0.1]|  0.0|[6.31969315070920...|[0.98476814297073...|       0.0|\n",
      "|[4.4,3.2,1.3,0.2]|  0.0|[6.25702868169002...|[0.98681724592628...|       0.0|\n",
      "|[4.6,3.2,1.4,0.2]|  0.0|[5.93084157354415...|[0.97943522015515...|       0.0|\n",
      "|[4.6,3.4,1.4,0.3]|  0.0|[6.17685212018133...|[0.98755830862849...|       0.0|\n",
      "|[4.8,3.0,1.4,0.1]|  0.0|[5.45569822648338...|[0.95223523625541...|       0.0|\n",
      "|[4.8,3.4,1.9,0.2]|  0.0|[5.66984003271475...|[0.97459279502617...|       0.0|\n",
      "|[4.9,3.0,1.4,0.2]|  0.0|[5.13373957470314...|[0.93814498244774...|       0.0|\n",
      "|[4.9,3.1,1.5,0.1]|  0.0|[5.47077891765211...|[0.95357883239289...|       0.0|\n",
      "|[4.9,3.1,1.5,0.1]|  0.0|[5.47077891765211...|[0.95357883239289...|       0.0|\n",
      "|[5.0,2.0,3.5,1.0]|  1.0|[-0.9451192912523...|[0.03944900910056...|       1.0|\n",
      "+-----------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict on the test set\n",
    "\n",
    "prediction = model.transform(test)\n",
    "print(\"Prediction\")\n",
    "prediction.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05a4b645-f8e0-4a43-bc89-276cb3f7a981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the accuracy of the model using the test set\n",
    "\n",
    "evaluator = pyspark.ml.evaluation.MulticlassClassificationEvaluator(metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(prediction)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e074af9b-b26f-41fd-919e-0fcf8dd5ce94",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "Similar story, just without the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55627cac-52c0-408e-ab69-b2e6abd878f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "km = pyspark.ml.clustering.KMeans(k=3)\n",
    "xs = data.select(['features'])\n",
    "clustering = km.fit(xs)\n",
    "labels = clustering.transform(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "441c3089-cffd-4d22-98bd-bd7a7e5b4e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+\n",
      "|         features|prediction|\n",
      "+-----------------+----------+\n",
      "|[5.1,3.5,1.4,0.2]|         1|\n",
      "|[4.9,3.0,1.4,0.2]|         1|\n",
      "|[4.7,3.2,1.3,0.2]|         1|\n",
      "|[4.6,3.1,1.5,0.2]|         1|\n",
      "|[5.0,3.6,1.4,0.2]|         1|\n",
      "|[5.4,3.9,1.7,0.4]|         1|\n",
      "|[4.6,3.4,1.4,0.3]|         1|\n",
      "|[5.0,3.4,1.5,0.2]|         1|\n",
      "|[4.4,2.9,1.4,0.2]|         1|\n",
      "|[4.9,3.1,1.5,0.1]|         1|\n",
      "+-----------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b31a20-86ea-4a5a-84c3-dbb90424335a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
