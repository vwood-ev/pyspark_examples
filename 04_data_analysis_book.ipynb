{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "090f0f15-2f05-4a65-8e27-4712ce120c04",
   "metadata": {},
   "source": [
    "## Examples from Data Analysis with Python and PySpark\n",
    "\n",
    "(A.K.A PySpark in Action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "238502ac-f26f-4dc4-9c3b-bc9c25cb76a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import urllib\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89f68071-7802-4710-87a2-258e7c65174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName(\"Analyzing vocabulary\")\n",
    "         .getOrCreate())\n",
    "\n",
    "# getOrCreate avoids creation of a new session, if one exists \n",
    "# but this may mean you can't change some JVM config options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e6f591-672c-4fd6-8334-3cb47f09f8cd",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c25ba647-acc2-49b0-8216-d5473893d3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./thoreau.txt', <http.client.HTTPMessage at 0x406f5da650>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.gutenberg.org/files/205/205-0.txt\"\n",
    "urllib.request.urlretrieve(url, './thoreau.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11f82506-dead-428c-86a5-2a1fea6f2d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "book = spark.read.text(\"./thoreau.txt\")\n",
    "\n",
    "book.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa8ef42e-c4ef-4d1b-8f0f-23a4b81a9a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        property\n",
       "\u001b[0;31mString form:\u001b[0m <property object at 0x406f810720>\n",
       "\u001b[0;31mDocstring:\u001b[0m  \n",
       "Returns a :class:`DataFrameReader` that can be used to read data\n",
       "in as a :class:`DataFrame`.\n",
       "\n",
       ".. versionadded:: 2.0.0\n",
       "\n",
       "Returns\n",
       "-------\n",
       ":class:`DataFrameReader`\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See docs\n",
    "!pyspark spark.read?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d22710c7-41ae-4399-8d9d-6a0ff94d4555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+\n",
      "|                                             value|\n",
      "+--------------------------------------------------+\n",
      "|The Project Gutenberg eBook of Walden, by Henry...|\n",
      "|                                                  |\n",
      "|This eBook is for the use of anyone anywhere in...|\n",
      "|most other parts of the world at no cost and wi...|\n",
      "|whatsoever. You may copy it, give it away or re...|\n",
      "|of the Project Gutenberg License included with ...|\n",
      "|www.gutenberg.org. If you are not located in th...|\n",
      "|will have to check the laws of the country wher...|\n",
      "|                                 using this eBook.|\n",
      "|                                                  |\n",
      "+--------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "book.show(10, truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dac9a50-52eb-42ea-b014-e736bac2c2d1",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f0740b1-02df-4a17-8675-049b1b67be79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+\n",
      "|                                              line|\n",
      "+--------------------------------------------------+\n",
      "|[The, Project, Gutenberg, eBook, of, Walden,, b...|\n",
      "|                                                []|\n",
      "|[This, eBook, is, for, the, use, of, anyone, an...|\n",
      "|[most, other, parts, of, the, world, at, no, co...|\n",
      "|[whatsoever., You, may, copy, it,, give, it, aw...|\n",
      "+--------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split the string by spaces, and change the name of the column\n",
    "# then select that one column\n",
    "lines = book.select(F.split(\"value\", \" \").alias(\"line\"))\n",
    "\n",
    "lines.show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3168d40d-18e7-4028-a7f0-1743a928b621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book.select(book.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ca738e5-9e6d-4a66-9d7d-2af8051d79e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book.select(book[\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66b113b2-b938-4e7d-9b93-5ddef433b585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book.select(col(\"value\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3df08ed7-deaf-4ba7-86be-2fd28d3f82b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book.select(\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a87b4b2-0dc3-49a9-80bc-7418cafeafe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     word|\n",
      "+---------+\n",
      "|      The|\n",
      "|  Project|\n",
      "|Gutenberg|\n",
      "|    eBook|\n",
      "|       of|\n",
      "|  Walden,|\n",
      "|       by|\n",
      "|    Henry|\n",
      "|    David|\n",
      "|  Thoreau|\n",
      "|         |\n",
      "|     This|\n",
      "|    eBook|\n",
      "|       is|\n",
      "|      for|\n",
      "+---------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# explode turns a column of vectors into a column, like ravel() in numpy\n",
    "\n",
    "words = lines.select(F.explode(\"line\").alias(\"word\"))\n",
    "\n",
    "words.show(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39af6a6-20c3-42ab-8d63-03b0bc7bc6f1",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad6a3c6e-e2ca-4ba3-b94b-90f20b720c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|word_lower|\n",
      "+----------+\n",
      "|       the|\n",
      "|   project|\n",
      "| gutenberg|\n",
      "|     ebook|\n",
      "|        of|\n",
      "|   walden,|\n",
      "|        by|\n",
      "|     henry|\n",
      "|     david|\n",
      "|   thoreau|\n",
      "|          |\n",
      "|      this|\n",
      "|     ebook|\n",
      "|        is|\n",
      "|       for|\n",
      "|       the|\n",
      "|       use|\n",
      "|        of|\n",
      "|    anyone|\n",
      "|  anywhere|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_lower = words.select(F.lower(\"word\").alias(\"word_lower\"))\n",
    "words_lower.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e0d330a-9c9a-4c55-85b4-2facf39d6518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     word|\n",
      "+---------+\n",
      "|      the|\n",
      "|  project|\n",
      "|gutenberg|\n",
      "|    ebook|\n",
      "|       of|\n",
      "|   walden|\n",
      "|       by|\n",
      "|    henry|\n",
      "|    david|\n",
      "|  thoreau|\n",
      "|         |\n",
      "|     this|\n",
      "|    ebook|\n",
      "|       is|\n",
      "|      for|\n",
      "|      the|\n",
      "|      use|\n",
      "|       of|\n",
      "|   anyone|\n",
      "| anywhere|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_clean = words_lower.select(\n",
    "    F.regexp_extract(\"word_lower\", \"[a-z]+\", 0).alias(\"word\")\n",
    ")\n",
    "\n",
    "words_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c737c15-2f17-4189-90a0-f703596eec2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     word|\n",
      "+---------+\n",
      "|      the|\n",
      "|  project|\n",
      "|gutenberg|\n",
      "|    ebook|\n",
      "|       of|\n",
      "|   walden|\n",
      "|       by|\n",
      "|    henry|\n",
      "|    david|\n",
      "|  thoreau|\n",
      "|     this|\n",
      "|    ebook|\n",
      "|       is|\n",
      "|      for|\n",
      "|      the|\n",
      "|      use|\n",
      "|       of|\n",
      "|   anyone|\n",
      "| anywhere|\n",
      "|       in|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You can use ~ operator to invert the filter expression\n",
    "words_nonull = words_clean.filter(F.col(\"word\") != \"\")\n",
    "\n",
    "words_nonull.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ad663e-0a73-48a0-82e3-7a5d43b2c7f6",
   "metadata": {},
   "source": [
    "## Count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55208baa-fed4-4c76-bb5b-6bc35656cf86",
   "metadata": {},
   "source": [
    "Spark groups records similar to pandas, allowing us to group all occurences of the same word, and count them up with an aggregation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff7fbf86-cccf-4aba-82aa-2791912c1f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = words_nonull.groupby(\"word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae2d52e9-34c3-44ff-bdc8-ef44ecb1c074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|         word|count|\n",
      "+-------------+-----+\n",
      "|       online|    4|\n",
      "|         some|  363|\n",
      "|        those|  137|\n",
      "|          few|   79|\n",
      "|        still|  173|\n",
      "|       poetry|   13|\n",
      "|          art|   23|\n",
      "|        trail|    5|\n",
      "|    arguments|    3|\n",
      "|    solemnity|    1|\n",
      "|          fog|    4|\n",
      "|       travel|   10|\n",
      "|gratification|    1|\n",
      "|       spared|    2|\n",
      "|        cures|    1|\n",
      "|      elevate|    1|\n",
      "|       marrow|    2|\n",
      "|    recognize|    8|\n",
      "|         hope|    8|\n",
      "|   strawberry|    2|\n",
      "+-------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = groups.count()\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30caed9d-948c-4cb2-a4df-183245dec010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|length|count|\n",
      "+------+-----+\n",
      "|    12|  539|\n",
      "|     1| 5186|\n",
      "|    13|  282|\n",
      "|     6| 9272|\n",
      "|    16|    3|\n",
      "|     3|27123|\n",
      "|     5|13954|\n",
      "|    15|   27|\n",
      "|     9| 3429|\n",
      "|    17|    2|\n",
      "|     4|21585|\n",
      "|     8| 4535|\n",
      "|     7| 7436|\n",
      "|    10| 2075|\n",
      "|    11| 1053|\n",
      "|    14|   77|\n",
      "|     2|22062|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Small exercise to return the counts of different lengths of word\n",
    "\n",
    "words_nonull.select(F.length(F.col(\"word\")).alias('length')).groupby(\"length\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40621770-dedd-4e78-9066-d9fc7b0bc116",
   "metadata": {},
   "source": [
    "## Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eff6ccbb-a7dc-45f5-b7cf-e41ac89d353a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "| word|count|\n",
      "+-----+-----+\n",
      "|  the| 7518|\n",
      "|  and| 4632|\n",
      "|   of| 3615|\n",
      "|   to| 3199|\n",
      "|    a| 3093|\n",
      "|   in| 2120|\n",
      "|    i| 1991|\n",
      "|   it| 1728|\n",
      "|   is| 1353|\n",
      "| that| 1340|\n",
      "|   as| 1223|\n",
      "|  not| 1073|\n",
      "|  for|  993|\n",
      "|   or|  956|\n",
      "| with|  925|\n",
      "|  was|  887|\n",
      "|which|  871|\n",
      "|  but|  805|\n",
      "|   my|  779|\n",
      "|   he|  765|\n",
      "+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    " results.orderBy(\"count\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c32d196-d86a-4995-9f03-ddfdf2a49a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'count_report': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm -r count_report\n",
    "!rm -r single_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12f5ad2f-cc24-478f-8821-416547dc628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice what actually gets written\n",
    "# We get an output file per partition of the data\n",
    "results.write.csv(\"./count_report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b916cb9-f4dd-441e-8808-c8d340d654c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./count_report/part-00000-35aad9c7-5f75-4e17-b0fc-cb2828deaf97-c000.csv\n",
      "./count_report/_SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!ls ./count_report/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51a864bb-02e2-43f6-adc3-b6a82f3b2cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all the data on a single partition\n",
    "results.coalesce(1).write.csv(\"./single_report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "961e46cd-96db-4581-91d2-c99f0e9d383e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./single_report/part-00000-46b642e5-5990-4fc4-89b5-a4d1980e7b99-c000.csv\n",
      "./single_report/_SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!ls ./single_report/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413a8583-af3e-43e4-96c1-757a3fc23c77",
   "metadata": {},
   "source": [
    "## All together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a21d61f-f9c7-408f-9e0f-e60e02ade643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that you could replace most of the F.col() calls with just the string\n",
    "# except: \"word\" != \"\" will fail in the .where() call\n",
    "\n",
    "report = (\n",
    "    spark.read.text(\"./thoreau.txt\")\n",
    "    .select(F.split(F.col(\"value\"), \" \").alias(\"line\"))\n",
    "    .select(F.explode(F.col(\"line\")).alias(\"word\"))\n",
    "    .select(F.lower(F.col(\"word\")).alias(\"word\"))\n",
    "    .select(F.regexp_extract(F.col(\"word\"), \"[a-z']*\", 0).alias(\"word\"))\n",
    "    .where(F.col(\"word\") != \"\")\n",
    "    .groupby(\"word\")\n",
    "    .count()\n",
    ")           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f0aabc-9a06-4f65-8159-ef691b447898",
   "metadata": {},
   "source": [
    "Jobs can be submitted also via spark-submit - convert this to a python script and run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2db1dbd-a8c1-4e3d-a7e6-09abfc67b6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!spark-submit exercise_04.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
