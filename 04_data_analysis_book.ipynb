{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "090f0f15-2f05-4a65-8e27-4712ce120c04",
   "metadata": {},
   "source": [
    "## Examples from Data Analysis with Python and PySpark\n",
    "\n",
    "(A.K.A PySpark in Action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "238502ac-f26f-4dc4-9c3b-bc9c25cb76a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import urllib\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.ml.feature import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89f68071-7802-4710-87a2-258e7c65174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName(\"Analyzing vocabulary\")\n",
    "         .getOrCreate())\n",
    "\n",
    "# getOrCreate avoids creation of a new session, if one exists \n",
    "# but this may mean you can't change some JVM config options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e6f591-672c-4fd6-8334-3cb47f09f8cd",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c25ba647-acc2-49b0-8216-d5473893d3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./thoreau.txt', <http.client.HTTPMessage at 0x406f5da650>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.gutenberg.org/files/205/205-0.txt\"\n",
    "urllib.request.urlretrieve(url, './thoreau.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11f82506-dead-428c-86a5-2a1fea6f2d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book = spark.read.text(\"./thoreau.txt\")\n",
    "\n",
    "book.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa8ef42e-c4ef-4d1b-8f0f-23a4b81a9a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        property\n",
       "\u001b[0;31mString form:\u001b[0m <property object at 0x406f810720>\n",
       "\u001b[0;31mDocstring:\u001b[0m  \n",
       "Returns a :class:`DataFrameReader` that can be used to read data\n",
       "in as a :class:`DataFrame`.\n",
       "\n",
       ".. versionadded:: 2.0.0\n",
       "\n",
       "Returns\n",
       "-------\n",
       ":class:`DataFrameReader`\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See docs\n",
    "!pyspark spark.read?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d22710c7-41ae-4399-8d9d-6a0ff94d4555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+\n",
      "|                                             value|\n",
      "+--------------------------------------------------+\n",
      "|The Project Gutenberg eBook of Walden, by Henry...|\n",
      "|                                                  |\n",
      "|This eBook is for the use of anyone anywhere in...|\n",
      "|most other parts of the world at no cost and wi...|\n",
      "|whatsoever. You may copy it, give it away or re...|\n",
      "|of the Project Gutenberg License included with ...|\n",
      "|www.gutenberg.org. If you are not located in th...|\n",
      "|will have to check the laws of the country wher...|\n",
      "|                                 using this eBook.|\n",
      "|                                                  |\n",
      "+--------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "book.show(10, truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dac9a50-52eb-42ea-b014-e736bac2c2d1",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f0740b1-02df-4a17-8675-049b1b67be79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+\n",
      "|                                              line|\n",
      "+--------------------------------------------------+\n",
      "|[The, Project, Gutenberg, eBook, of, Walden,, b...|\n",
      "|                                                []|\n",
      "|[This, eBook, is, for, the, use, of, anyone, an...|\n",
      "|[most, other, parts, of, the, world, at, no, co...|\n",
      "|[whatsoever., You, may, copy, it,, give, it, aw...|\n",
      "+--------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split\n",
    "\n",
    "# split the string by spaces, and change the name of the column\n",
    "# then select that one column\n",
    "lines = book.select(split(book.value, \" \").alias(\"line\"))\n",
    "\n",
    "lines.show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3168d40d-18e7-4028-a7f0-1743a928b621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book.select(book.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ca738e5-9e6d-4a66-9d7d-2af8051d79e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book.select(book[\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66b113b2-b938-4e7d-9b93-5ddef433b585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book.select(col(\"value\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3df08ed7-deaf-4ba7-86be-2fd28d3f82b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book.select(\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a87b4b2-0dc3-49a9-80bc-7418cafeafe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     word|\n",
      "+---------+\n",
      "|      The|\n",
      "|  Project|\n",
      "|Gutenberg|\n",
      "|    eBook|\n",
      "|       of|\n",
      "|  Walden,|\n",
      "|       by|\n",
      "|    Henry|\n",
      "|    David|\n",
      "|  Thoreau|\n",
      "|         |\n",
      "|     This|\n",
      "|    eBook|\n",
      "|       is|\n",
      "|      for|\n",
      "+---------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode, col\n",
    "\n",
    "# explode turns a column of vectors into a column, like ravel() in numpy\n",
    "\n",
    "words = lines.select(explode(col(\"line\")).alias(\"word\"))\n",
    "\n",
    "words.show(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39af6a6-20c3-42ab-8d63-03b0bc7bc6f1",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad6a3c6e-e2ca-4ba3-b94b-90f20b720c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|word_lower|\n",
      "+----------+\n",
      "|       the|\n",
      "|   project|\n",
      "| gutenberg|\n",
      "|     ebook|\n",
      "|        of|\n",
      "|   walden,|\n",
      "|        by|\n",
      "|     henry|\n",
      "|     david|\n",
      "|   thoreau|\n",
      "|          |\n",
      "|      this|\n",
      "|     ebook|\n",
      "|        is|\n",
      "|       for|\n",
      "|       the|\n",
      "|       use|\n",
      "|        of|\n",
      "|    anyone|\n",
      "|  anywhere|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lower\n",
    "\n",
    "words_lower = words.select(lower(col(\"word\")).alias(\"word_lower\"))\n",
    "words_lower.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e0d330a-9c9a-4c55-85b4-2facf39d6518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     word|\n",
      "+---------+\n",
      "|      the|\n",
      "|  project|\n",
      "|gutenberg|\n",
      "|    ebook|\n",
      "|       of|\n",
      "|   walden|\n",
      "|       by|\n",
      "|    henry|\n",
      "|    david|\n",
      "|  thoreau|\n",
      "|         |\n",
      "|     this|\n",
      "|    ebook|\n",
      "|       is|\n",
      "|      for|\n",
      "|      the|\n",
      "|      use|\n",
      "|       of|\n",
      "|   anyone|\n",
      "| anywhere|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "words_clean = words_lower.select(\n",
    "    regexp_extract(col(\"word_lower\"), \"[a-z]+\", 0).alias(\"word\")\n",
    ")\n",
    "\n",
    "words_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c737c15-2f17-4189-90a0-f703596eec2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     word|\n",
      "+---------+\n",
      "|      the|\n",
      "|  project|\n",
      "|gutenberg|\n",
      "|    ebook|\n",
      "|       of|\n",
      "|   walden|\n",
      "|       by|\n",
      "|    henry|\n",
      "|    david|\n",
      "|  thoreau|\n",
      "|     this|\n",
      "|    ebook|\n",
      "|       is|\n",
      "|      for|\n",
      "|      the|\n",
      "|      use|\n",
      "|       of|\n",
      "|   anyone|\n",
      "| anywhere|\n",
      "|       in|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use ~ operator to invert the filter expression\n",
    "words_nonull = words_clean.filter(col(\"word\") != \"\")\n",
    "\n",
    "words_nonull.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ad663e-0a73-48a0-82e3-7a5d43b2c7f6",
   "metadata": {},
   "source": [
    "## Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7fbf86-cccf-4aba-82aa-2791912c1f85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
