{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b66a3ca-ddf1-4945-bd8b-8084cb55d17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import urllib\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.ml.feature import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53703df4-32f1-48a5-b873-8bbe92552559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PySpark Version :3.3.0\n",
      "PySpark Version :3.3.0\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('example').getOrCreate()\n",
    "\n",
    "print('PySpark Version :' + spark.version)\n",
    "print('PySpark Version :' + spark.sparkContext.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07d0e526-5bdf-4052-9d3c-a53a0ed68a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./20_newsgroups.tar.gz', <http.client.HTTPMessage at 0x408342fb80>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/20newsgroups-mld/20_newsgroups.tar.gz\"\n",
    "urllib.request.urlretrieve(URL, './20_newsgroups.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b3b2bad-41aa-49ad-889b-b2cf9a6241dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('file:/home/jovyan/work/Iris_example.ipynb', 11758),\n",
       " ('file:/home/jovyan/work/Untitled.ipynb', 3531),\n",
       " ('file:/home/jovyan/work/iris.csv', 4551),\n",
       " ('file:/home/jovyan/work/test.txt', 14)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# binaryFiles reads all files in the given path - returning [(filenames, bytes) ...]\n",
    "\n",
    "spark.sparkContext.binaryFiles(\"./\").map(lambda x: (x[0], len(x[1]))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "07a49201-fc8a-4b2c-b2d6-fcd3c1151b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "from io import BytesIO\n",
    "\n",
    "def extract_files(data):\n",
    "    filename, bytes = data\n",
    "    tar = tarfile.open(fileobj=BytesIO(bytes), mode=\"r:gz\")\n",
    "    for x in tar:\n",
    "        if not x.isfile():\n",
    "            continue\n",
    "        yield (x.name, tar.extractfile(x).read())\n",
    "\n",
    "data = (spark.sparkContext.binaryFiles(\"./20_newsgroups.tar.gz\")\n",
    "        .flatMap(extract_files)\n",
    "        .mapValues(lambda x: x.decode(\"latin-1\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7c434470-f993-4a1f-89c0-cb99096e99a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('20_newsgroups/alt.atheism/53366', 1926),\n",
       " ('20_newsgroups/alt.atheism/53367', 2456),\n",
       " ('20_newsgroups/alt.atheism/51247', 2144),\n",
       " ('20_newsgroups/alt.atheism/51248', 929),\n",
       " ('20_newsgroups/alt.atheism/51249', 1976),\n",
       " ('20_newsgroups/alt.atheism/51250', 3325),\n",
       " ('20_newsgroups/alt.atheism/51251', 1421),\n",
       " ('20_newsgroups/alt.atheism/51252', 2310),\n",
       " ('20_newsgroups/alt.atheism/51253', 3664),\n",
       " ('20_newsgroups/alt.atheism/51254', 3392)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.map(lambda x: (x[0], len(x[1]))).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d9d8dc32-d627-48cf-95c4-8a0d29c610ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) PythonRDD[73] at RDD at PythonRDD.scala:53 []\n",
      " |  ./20_newsgroups.tar.gz BinaryFileRDD[71] at binaryFiles at <unknown>:0 []\n"
     ]
    }
   ],
   "source": [
    "# Decent way of seeing the lineage structure of RDDs\n",
    "print(data.toDebugString().decode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e7718d13-c3e8-44dc-86ea-0e163a24589c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert RDD to dataframe\n",
    "\n",
    "df = data.toDF(['filename', 'bytes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "af6d679a-60e4-4c51-9e7a-046d5f89ce05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            filename|               bytes|\n",
      "+--------------------+--------------------+\n",
      "|20_newsgroups/alt...|Path: cantaloupe....|\n",
      "|20_newsgroups/alt...|Xref: cantaloupe....|\n",
      "|20_newsgroups/alt...|Newsgroups: alt.a...|\n",
      "|20_newsgroups/alt...|Xref: cantaloupe....|\n",
      "|20_newsgroups/alt...|Path: cantaloupe....|\n",
      "|20_newsgroups/alt...|Newsgroups: alt.a...|\n",
      "|20_newsgroups/alt...|Newsgroups: alt.a...|\n",
      "|20_newsgroups/alt...|Xref: cantaloupe....|\n",
      "|20_newsgroups/alt...|Newsgroups: alt.a...|\n",
      "|20_newsgroups/alt...|Path: cantaloupe....|\n",
      "+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eadcd79-6fd2-4860-ac33-096b3ec59979",
   "metadata": {},
   "source": [
    "# Spark ML on text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83020267-a1f4-453e-968c-306219508ba6",
   "metadata": {},
   "source": [
    "## Feature Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b04c1d7-e2fe-40cb-b630-24b39b03a185",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "da499658-09df-4c01-aab1-a5934fe55205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(filename='20_newsgroups/alt.atheism/53366', bytes='Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!noc.near.net!howland.reston.ans.net!usenet.ins.cwru.edu!lerc.nasa.gov!usenet\\nFrom: spbach@lerc.nasa.gov (James Felder)\\nNewsgroups: alt.atheism\\nSubject: Re: \"So help you God\" in court?\\nDate: 16 Apr 1993 13:54:45 GMT\\nOrganization: NASA Lewis Resaerch Center\\nLines: 35\\nDistribution: world\\nMessage-ID: <1qmdr5$ang@eagle.lerc.nasa.gov>\\nReferences: <93105.013423TAN102@psuvm.psu.edu>\\nReply-To: spbach@lerc.nasa.gov\\nNNTP-Posting-Host: hopper3.lerc.nasa.gov\\n\\nIn article 013423TAN102@psuvm.psu.edu, Andrew Newell <TAN102@psuvm.psu.edu> writes:\\n->In article <1993Apr9.151914.1885@daffy.cs.wisc.edu>, mccullou@snake2.cs.wisc.edu\\n->(Mark McCullough) says:\\n->>\\n->>In article <monack.733980580@helium> monack@helium.gas.uug.arizona.edu (david\\n->>n->>monack) writes:\\n->>>Another issue is that by having to request to not be required to\\n->>>recite the \"so help me God\" part of the oath, a theistic jury may be\\n->>>prejudiced against your testimony even though atheism is probably not\\n->>>at all relevant to the case.\\n->>>\\n->>>What is the recommended procedure for requesting an alternate oath or\\n->>>affirmation?\\n->>>\\n->>>Dave\\n\\nSorry for using a follow-up to respond, but my server dropped about a weeks worth of news\\nwhen it couldn\\'t keep up.\\n\\nWhen the you are asked to swear \"So help you god\" and you have to say it, ask which one; Jesus,\\nAllah, Vishnu, Zues, Odin.  Get them to be specific.   Don\\'t be obnoxious, just humbly ask, then \\nquitely sit back and watch the fun.\\n\\n---\\n\\n-----------------------------------------------------------------------------\\nJames L. Felder\\t\\t\\t|\\nSverdrup Technology,Inc.\\t|     phone: 216-891-4019\\nNASA Lewis Research Center     \\t|    \\nCleveland, Ohio  44135         \\t|     email: jfelder@lerc.nasa.gov \\n\"Some people drink from the fountain of knowledge, other people gargle\"\\n-----------------------------------------------------------------------------\\n\\n\\n\\n', words=['path:', 'cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!noc.near.net!howland.reston.ans.net!usenet.ins.cwru.edu!lerc.nasa.gov!usenet', 'from:', 'spbach@lerc.nasa.gov', '(james', 'felder)', 'newsgroups:', 'alt.atheism', 'subject:', 're:', '\"so', 'help', 'you', 'god\"', 'in', 'court?', 'date:', '16', 'apr', '1993', '13:54:45', 'gmt', 'organization:', 'nasa', 'lewis', 'resaerch', 'center', 'lines:', '35', 'distribution:', 'world', 'message-id:', '<1qmdr5$ang@eagle.lerc.nasa.gov>', 'references:', '<93105.013423tan102@psuvm.psu.edu>', 'reply-to:', 'spbach@lerc.nasa.gov', 'nntp-posting-host:', 'hopper3.lerc.nasa.gov', '', 'in', 'article', '013423tan102@psuvm.psu.edu,', 'andrew', 'newell', '<tan102@psuvm.psu.edu>', 'writes:', '->in', 'article', '<1993apr9.151914.1885@daffy.cs.wisc.edu>,', 'mccullou@snake2.cs.wisc.edu', '->(mark', 'mccullough)', 'says:', '->>', '->>in', 'article', '<monack.733980580@helium>', 'monack@helium.gas.uug.arizona.edu', '(david', '->>n->>monack)', 'writes:', '->>>another', 'issue', 'is', 'that', 'by', 'having', 'to', 'request', 'to', 'not', 'be', 'required', 'to', '->>>recite', 'the', '\"so', 'help', 'me', 'god\"', 'part', 'of', 'the', 'oath,', 'a', 'theistic', 'jury', 'may', 'be', '->>>prejudiced', 'against', 'your', 'testimony', 'even', 'though', 'atheism', 'is', 'probably', 'not', '->>>at', 'all', 'relevant', 'to', 'the', 'case.', '->>>', '->>>what', 'is', 'the', 'recommended', 'procedure', 'for', 'requesting', 'an', 'alternate', 'oath', 'or', '->>>affirmation?', '->>>', '->>>dave', '', 'sorry', 'for', 'using', 'a', 'follow-up', 'to', 'respond,', 'but', 'my', 'server', 'dropped', 'about', 'a', 'weeks', 'worth', 'of', 'news', 'when', 'it', \"couldn't\", 'keep', 'up.', '', 'when', 'the', 'you', 'are', 'asked', 'to', 'swear', '\"so', 'help', 'you', 'god\"', 'and', 'you', 'have', 'to', 'say', 'it,', 'ask', 'which', 'one;', 'jesus,', 'allah,', 'vishnu,', 'zues,', 'odin.', '', 'get', 'them', 'to', 'be', 'specific.', '', '', \"don't\", 'be', 'obnoxious,', 'just', 'humbly', 'ask,', 'then', '', 'quitely', 'sit', 'back', 'and', 'watch', 'the', 'fun.', '', '---', '', '-----------------------------------------------------------------------------', 'james', 'l.', 'felder', '', '', '|', 'sverdrup', 'technology,inc.', '|', '', '', '', '', 'phone:', '216-891-4019', 'nasa', 'lewis', 'research', 'center', '', '', '', '', '', '|', '', '', '', '', 'cleveland,', 'ohio', '', '44135', '', '', '', '', '', '', '', '', '', '|', '', '', '', '', 'email:', 'jfelder@lerc.nasa.gov', '', '\"some', 'people', 'drink', 'from', 'the', 'fountain', 'of', 'knowledge,', 'other', 'people', 'gargle\"', '-----------------------------------------------------------------------------'])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(inputCol='bytes', outputCol='words')\n",
    "\n",
    "tokenizer.transform(df).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff655df3-c0c2-41bb-8f37-744918a1482c",
   "metadata": {},
   "source": [
    "### Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235b300b-d98b-492e-840c-7a5c8aaacf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Word2Vec\n",
    "\n",
    "word2vec = Word2Vec(vectorSize=30, minCount=5, inputCol='bytes', outputCol='embedding')\n",
    "model = word2vec.fit(df)\n",
    "\n",
    "result = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c060d1e-a7ba-4ea5-88b1-6fc6b820eda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in result.take(5):\n",
    "    text, vector = row\n",
    "    print(f\"Text:   {text[:100]}...\")\n",
    "    print(f\"Vector: {vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83addc97-801e-434a-b732-6cc6388dce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "Row(text='a b c', words=['a', 'b', 'c'])\n",
    "\n",
    "# Change a parameter.\n",
    "\n",
    "tokenizer.setParams(outputCol=\"tokens\").transform(df).head()\n",
    "Row(text='a b c', tokens=['a', 'b', 'c'])\n",
    "\n",
    "# Temporarily modify a parameter.\n",
    "\n",
    "tokenizer.transform(df, {tokenizer.outputCol: \"words\"}).head()\n",
    "Row(text='a b c', words=['a', 'b', 'c'])\n",
    "\n",
    "tokenizer.transform(df).head()\n",
    "Row(text='a b c', tokens=['a', 'b', 'c'])\n",
    "\n",
    "# Must use keyword arguments to specify params.\n",
    "\n",
    "tokenizer.setParams(\"text\")\n",
    "Traceback (most recent call last):\n",
    "    ...\n",
    "TypeError: Method setParams forces keyword arguments.\n",
    "\n",
    "tokenizerPath = temp_path + \"/tokenizer\"\n",
    "\n",
    "tokenizer.save(tokenizerPath)\n",
    "\n",
    "loadedTokenizer = Tokenizer.load(tokenizerPath)\n",
    "\n",
    "loadedTokenizer.transform(df).head().tokens == tokenizer.transform(df).head().tokens\n",
    "True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9e8636-f0c7-4a48-8e98-2411d61d98c9",
   "metadata": {},
   "source": [
    "# Spark-NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f55786c-0f05-45f4-9b08-9e326340118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spark-nlp==4.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ed6d3a-17c5-4311-aa7d-61b73e037323",
   "metadata": {},
   "outputs": [],
   "source": [
    "!spark-shell --packages com.johnsnowlabs.nlp:spark-nlp-m1_2.12:4.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711bd131-bafa-4ce0-9439-e89773369c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pyspark --packages com.johnsnowlabs.nlp:spark-nlp-m1_2.12:4.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3752f143-8e98-49bd-85bb-a23d70b77555",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder.appName('example')\n",
    "         .config('spark.jars.packages', 'com.johnsnowlabs.nlp:spark-nlp-m1_2.12:4.1.0')\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ce44f6-4500-48a6-b73a-0dbe6148e3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "\n",
    "pipeline = PretrainedPipeline('recognize_entities_dl', 'en')\n",
    "\n",
    "result = pipeline.annotate('President Biden represented Delaware for 36 years in the U.S. Senate before becoming the 47th Vice President of the United States.') \n",
    "\n",
    "print(result['ner'])\n",
    "print(result['entities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f989e-c197-4be8-90ec-535b91be4200",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = PretrainedPipeline('onto_recognize_entities_bert_tiny', 'en')\n",
    "\n",
    "result = pipeline.annotate(\"Johnson first entered politics when elected in 2001 as a member of Parliament. He then served eight years as the mayor of London, from 2008 to 2016, before rejoining Parliament.\")\n",
    "\n",
    "print(result['ner'])\n",
    "print(result['entities'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
