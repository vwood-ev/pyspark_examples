{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d183fc1f-47f6-456c-8fd1-21a0db30a1a3",
   "metadata": {},
   "source": [
    "# Working with fraud datasets for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddb9012-24ca-4043-8ed0-4c829768c37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import urllib\n",
    "import pylab as pl\n",
    "import seaborn as sns\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.ml.feature import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c3aaa5-3ecb-4591-bee7-1716c073e8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('eda').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa3903d-44cc-412b-958d-8b2f8d795685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloaded a bunch of datasets from kaggle / similar\n",
    "glob.glob(\"dataset/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9894dfcb-246a-4c9d-89fd-c99f3c7c94de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inferSchema reads the file twice, but detects numerical columns\n",
    "data = spark.read.csv('dataset/creditcard_2023.csv', header=True, inferSchema=True)\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b6559b-3620-439f-9bc2-6cb67f557702",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd48bc04-00f4-45c2-9770-f10d9428a3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1e54db-c19d-428d-8702-ffdb7de65399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature column\n",
    "\n",
    "feature_cols = data.columns[1:-2]\n",
    "assembler = pyspark.ml.feature.VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
    "data = assembler.transform(data)\n",
    "data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30da515f-e7da-40f9-9977-5130dda492bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.select(['features', 'Class'])\n",
    "data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ad3f5d-cde4-4d37-b9cb-a548f4ac5395",
   "metadata": {},
   "outputs": [],
   "source": [
    "km = pyspark.ml.clustering.KMeans(k=3)\n",
    "xs = data.select(['features'])\n",
    "clustering = km.fit(xs)\n",
    "labels = clustering.transform(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e553eb6a-5c9c-4c19-820d-2e84a92fec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.groupBy('prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01286d6-9d0c-4953-97c3-1d2608e5b56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.select(['prediction']).summary().show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b3404b-1910-4e3a-8e28-52e3f950e719",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311aa350-ff29-4ab1-8841-1b0076c45a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0155b8ee-e7b5-4dfb-9eaa-66acdbcf905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2956ead0-65e2-4b01-a739-a021d915a14b",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586fcac8-937a-4716-b3fe-2416f38a215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = data.select(['features'])\n",
    "\n",
    "scaler = StandardScaler(\n",
    "    inputCol = 'features', \n",
    "    outputCol = 'scaledFeatures',\n",
    "    withMean = True,\n",
    "    withStd = True\n",
    ").fit(xs)\n",
    "\n",
    "xs_scaled = scaler.transform(xs)\n",
    "xs_scaled.show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c284cd-5288-47ac-a43f-f9094151ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 2\n",
    "pca = PCA(\n",
    "    k = n_components, \n",
    "    inputCol = 'scaledFeatures', \n",
    "    outputCol = 'pcaFeatures'\n",
    ").fit(xs_scaled)\n",
    "\n",
    "xs_pca = pca.transform(xs_scaled)\n",
    "print('Explained Variance Ratio', pca.explainedVariance.toArray())\n",
    "xs_pca.show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f4455a-130e-4da0-91ff-4b27be16575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull back to \"local machine\"\n",
    "local_xs = xs_pca.rdd.map(lambda row: row.pcaFeatures).collect()\n",
    "local_xs = np.array(local_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd7e520-3caf-4c14-9610-d8e9f3ce9608",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_y = np.array(data.select('Class').collect()).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888c99aa-aac6-4f5a-b974-b689b2483c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.scatter(local_xs[:, 0], local_xs[:, 1], s=8, alpha=0.3, c=local_y)\n",
    "pl.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6987ced7-b80a-4cf3-a49f-44cceea91108",
   "metadata": {},
   "source": [
    "## Second dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2217eb93-316d-4ba9-9056-396a9daf23b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('dataset/detect/creditcard_train.csv', header=True, inferSchema=True)\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeac3ae-e43a-4da0-86d1-37466d8f31dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = data.columns[1:-1]\n",
    "assembler = pyspark.ml.feature.VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
    "data = assembler.transform(data)\n",
    "data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ce6bcb-7201-416c-bcf0-9e38bfee546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = data.select(['features'])\n",
    "\n",
    "scaler = StandardScaler(\n",
    "    inputCol = 'features', \n",
    "    outputCol = 'scaledFeatures',\n",
    "    withMean = True,\n",
    "    withStd = True\n",
    ").fit(xs)\n",
    "\n",
    "xs_scaled = scaler.transform(xs)\n",
    "xs_scaled.show(6)\n",
    "\n",
    "n_components = 2\n",
    "pca = PCA(\n",
    "    k = n_components, \n",
    "    inputCol = 'scaledFeatures', \n",
    "    outputCol = 'pcaFeatures'\n",
    ").fit(xs_scaled)\n",
    "\n",
    "xs_pca = pca.transform(xs_scaled)\n",
    "print('Explained Variance Ratio', pca.explainedVariance.toArray())\n",
    "xs_pca.show(6)\n",
    "\n",
    "# pull back to \"local machine\"\n",
    "local_xs = xs_pca.rdd.map(lambda row: row.pcaFeatures).collect()\n",
    "local_xs = np.array(local_xs)\n",
    "\n",
    "local_y = np.array(data.select('Class').collect()).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcc1dab-39cf-4643-b621-95f9a81cb075",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.scatter(local_xs[:, 0], local_xs[:, 1], s=8, alpha=0.3, c=local_y)\n",
    "pl.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2d5d1c-88c8-430b-b92d-b601613313df",
   "metadata": {},
   "source": [
    "## Third dataset\n",
    "More complex, text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4487c734-2916-42a7-9926-f48f457e5d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('dataset/insurance/train.csv', header=True, inferSchema=True)\n",
    "data.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
